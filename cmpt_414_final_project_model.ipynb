{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cmpt-414-final-project-model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hgdsraj/AI-Facial-Feature-Detection/blob/master/cmpt_414_final_project_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "369fa247a546e39d82bdfdc5b7d4ed58baa40e4f",
        "id": "L020VK2Yu2Hr",
        "colab_type": "code",
        "outputId": "a3e0708e-1723-49cf-e0cb-1ce1da8b4664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.layers import PReLU, LeakyReLU\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqhCh10zkmZJ",
        "colab_type": "code",
        "outputId": "426c9098-8ece-427a-d879-ab7c48a5e1c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "os.listdir('/content/drive/My Drive/417data')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SampleSubmission.csv',\n",
              " 'IdLookupTable.csv',\n",
              " 'test.csv',\n",
              " 'training.csv',\n",
              " 'val_acc_test.txt',\n",
              " 'training_mean.csv',\n",
              " 'old_model.json',\n",
              " 'good_model.h5',\n",
              " 'good_model.json',\n",
              " 'old_model.h5',\n",
              " 'val_acc.txt',\n",
              " 'model.json',\n",
              " 'model.h5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "fa1b76273d02502e3fd668dddf74ecf522044524",
        "id": "tje_6dfQu2Hu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train_Dir = '/content/drive/My Drive/417data/training.csv'\n",
        "Test_Dir = '/content/drive/My Drive/417data/test.csv'\n",
        "Lookup_Table_Dir = '/content/drive/My Drive/417data/IdLookupTable.csv'\n",
        "train_data = pd.read_csv(Train_Dir)  \n",
        "lookup_table_data = pd.read_csv(Lookup_Table_Dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyOsM6ari7uB",
        "colab_type": "code",
        "outputId": "b58d6f0e-0499-41ce-f0a2-2c0d7cab2c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#check for missing values\n",
        "train_data.isnull().any().value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     28\n",
              "False     3\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sUU457Gi9b8",
        "colab_type": "code",
        "outputId": "1ebac1d6-3d4c-4da1-8d16-f176212f6120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# fill missing data with frontfill -> then backfill \n",
        "train_data.fillna(method = 'ffill',inplace = True)\n",
        "train_data.fillna(method = 'bfill',inplace = True)\n",
        "\n",
        "train_data.isnull().any().value_counts() # ensure none remain"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    31\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "e78ca4523425835f1b584f3e30e5c9dcc8014253",
        "id": "ZRD65x94u2IC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imag = []\n",
        "for i in range(0,len(train_data['Image'])):\n",
        "    img = train_data['Image'][i].split(' ')\n",
        "    img = ['0' if x == '' else x for x in img]\n",
        "    imag.append(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "da09436050dc2df5da7cb49ad90125b1b756f1a4",
        "id": "PD4gXLL0u2IF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reshape to 96 by 96 float (img size)\n",
        "image_list = np.array(imag,dtype = 'float')\n",
        "X_train = image_list.reshape(-1,96,96,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "e9d804a035809cdf8ffda19f41ce3feb278a38fb",
        "id": "C4dyN_alu2IM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training = train_data.drop('Image',axis = 1)\n",
        "\n",
        "y_train = []\n",
        "for i in range(0,len(train_data['Image'])):\n",
        "    y = training.iloc[i,:]\n",
        "\n",
        "    y_train.append(y)\n",
        "y_train = np.array(y_train,dtype = 'float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NBy2f9Ld88M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"\"\"TRAIN VALIDATION SPLIT\"\"\"\n",
        "# y_validation = y_train[-1409:]\n",
        "# y_train = y_train[:-1409]\n",
        "\n",
        "# X_validation = X_train[-1409:]\n",
        "# X_train = X_train[:-1409]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SNskqB2Yu2IV",
        "colab_type": "code",
        "outputId": "0f4f5c83-dd02-4866-e86b-b40c630926ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(BatchNormalization(input_shape=(96, 96, 1)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_initializer=\"he_normal\", use_bias=False, input_shape=(96,96,1)))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, (3,3), padding='same', use_bias=False, kernel_regularizer=regularizers.l1_l2(l1 = 0.0005, l2=0.00005)))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, (3,3), padding='same', use_bias=False, kernel_regularizer=regularizers.l1_l2(l1 = 0.0005, l2=0.00005)))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, (3,3), padding='same', use_bias=False, kernel_regularizer=regularizers.l1_l2(l1 = 0.0005, l2=0.00005)))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding=\"same\"))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', use_bias=False))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', use_bias=False))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', use_bias=False))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', use_bias=False))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding=\"valid\"))\n",
        "\n",
        "model.add(Conv2D(96, (3,3), padding='same', use_bias=False))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(96, (3,3), padding='same', use_bias=False))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding=\"valid\"))\n",
        "\n",
        "model.add(Conv2D(128, (3,3),padding='same', use_bias=False))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, (3,3),padding='same', use_bias=False))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding=\"same\"))\n",
        "\n",
        "model.add(Conv2D(256, (3,3),padding='same',use_bias=False))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(256, (3,3),padding='same',use_bias=False))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding=\"same\"))\n",
        "\n",
        "model.add(Conv2D(512, (3,3), padding='same', use_bias=False))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, (3,3), padding='same', use_bias=False))\n",
        "model.add(PReLU(alpha_initializer='zeros'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu', kernel_regularizer=regularizers.l1_l2(l1 = 0.0005, l2=0.00005)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(90,activation='relu'))\n",
        "\n",
        "model.add(Dense(30))\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 96, 1)         4         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 96, 32)        288       \n",
            "_________________________________________________________________\n",
            "p_re_lu (PReLU)              (None, 96, 96, 32)        294912    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 96, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 96, 96, 32)        9216      \n",
            "_________________________________________________________________\n",
            "p_re_lu_1 (PReLU)            (None, 96, 96, 32)        294912    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 96, 96, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 96, 96, 32)        9216      \n",
            "_________________________________________________________________\n",
            "p_re_lu_2 (PReLU)            (None, 96, 96, 32)        294912    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 96, 96, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 96, 96, 32)        9216      \n",
            "_________________________________________________________________\n",
            "p_re_lu_3 (PReLU)            (None, 96, 96, 32)        294912    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 96, 96, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 48, 48, 64)        18432     \n",
            "_________________________________________________________________\n",
            "p_re_lu_4 (PReLU)            (None, 48, 48, 64)        147456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 48, 48, 64)        36864     \n",
            "_________________________________________________________________\n",
            "p_re_lu_5 (PReLU)            (None, 48, 48, 64)        147456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 48, 48, 64)        36864     \n",
            "_________________________________________________________________\n",
            "p_re_lu_6 (PReLU)            (None, 48, 48, 64)        147456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 48, 48, 64)        36864     \n",
            "_________________________________________________________________\n",
            "p_re_lu_7 (PReLU)            (None, 48, 48, 64)        147456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 24, 24, 96)        55296     \n",
            "_________________________________________________________________\n",
            "p_re_lu_8 (PReLU)            (None, 24, 24, 96)        55296     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 24, 24, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 24, 24, 96)        82944     \n",
            "_________________________________________________________________\n",
            "p_re_lu_9 (PReLU)            (None, 24, 24, 96)        55296     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 24, 24, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 12, 12, 128)       110592    \n",
            "_________________________________________________________________\n",
            "p_re_lu_10 (PReLU)           (None, 12, 12, 128)       18432     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 12, 12, 128)       147456    \n",
            "_________________________________________________________________\n",
            "p_re_lu_11 (PReLU)           (None, 12, 12, 128)       18432     \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 6, 6, 256)         294912    \n",
            "_________________________________________________________________\n",
            "p_re_lu_12 (PReLU)           (None, 6, 6, 256)         9216      \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 6, 6, 256)         589824    \n",
            "_________________________________________________________________\n",
            "p_re_lu_13 (PReLU)           (None, 6, 6, 256)         9216      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 3, 3, 512)         1179648   \n",
            "_________________________________________________________________\n",
            "p_re_lu_14 (PReLU)           (None, 3, 3, 512)         4608      \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 3, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 3, 3, 512)         2359296   \n",
            "_________________________________________________________________\n",
            "p_re_lu_15 (PReLU)           (None, 3, 3, 512)         4608      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 3, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               2359808   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 90)                46170     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 30)                2730      \n",
            "=================================================================\n",
            "Total params: 9,339,688\n",
            "Trainable params: 9,334,950\n",
            "Non-trainable params: 4,738\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AFfhd2Tgu2IY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='mse', # TODO mean_squared_error ? \n",
        "              metrics=['mae', 'accuracy']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "894af9cbfcf2dca50e7407946cad318157b77d0a",
        "id": "A1KDWm78u2Ib",
        "colab_type": "code",
        "outputId": "7ea7ad72-b336-45ce-c19f-51f185217f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train,y_train,epochs = 400, batch_size = 256, validation_split=0.2, use_multiprocessing = True, workers=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "23/23 [==============================] - 10s 418ms/step - loss: 675.6827 - mae: 18.5121 - accuracy: 0.0679 - val_loss: 121.3105 - val_mae: 8.3732 - val_accuracy: 0.3121\n",
            "Epoch 2/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 57.3406 - mae: 4.7069 - accuracy: 0.4494 - val_loss: 45.4066 - val_mae: 3.8500 - val_accuracy: 0.6872\n",
            "Epoch 3/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 43.5526 - mae: 3.7118 - accuracy: 0.4260 - val_loss: 35.6604 - val_mae: 3.1770 - val_accuracy: 0.6872\n",
            "Epoch 4/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 40.5417 - mae: 3.5648 - accuracy: 0.4613 - val_loss: 25.0835 - val_mae: 1.7013 - val_accuracy: 0.6872\n",
            "Epoch 5/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 36.1748 - mae: 3.2285 - accuracy: 0.4747 - val_loss: 30.2493 - val_mae: 2.8001 - val_accuracy: 0.6872\n",
            "Epoch 6/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 34.8376 - mae: 3.1619 - accuracy: 0.4827 - val_loss: 27.2669 - val_mae: 2.5004 - val_accuracy: 0.6872\n",
            "Epoch 7/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 33.2753 - mae: 3.0579 - accuracy: 0.4996 - val_loss: 27.9373 - val_mae: 2.7245 - val_accuracy: 0.6872\n",
            "Epoch 8/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 31.2470 - mae: 2.9695 - accuracy: 0.5068 - val_loss: 21.4276 - val_mae: 1.6935 - val_accuracy: 0.6872\n",
            "Epoch 9/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 30.1449 - mae: 2.9480 - accuracy: 0.5098 - val_loss: 27.3210 - val_mae: 2.9021 - val_accuracy: 0.6872\n",
            "Epoch 10/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 28.3443 - mae: 2.8019 - accuracy: 0.5412 - val_loss: 18.6882 - val_mae: 1.3632 - val_accuracy: 0.6851\n",
            "Epoch 11/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 27.2425 - mae: 2.7974 - accuracy: 0.5772 - val_loss: 21.0747 - val_mae: 2.0205 - val_accuracy: 0.6801\n",
            "Epoch 12/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 25.9345 - mae: 2.6876 - accuracy: 0.6265 - val_loss: 17.7953 - val_mae: 1.3763 - val_accuracy: 0.6582\n",
            "Epoch 13/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 26.6713 - mae: 2.7825 - accuracy: 0.6549 - val_loss: 28.7826 - val_mae: 3.1516 - val_accuracy: 0.5397\n",
            "Epoch 14/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 25.2938 - mae: 2.7423 - accuracy: 0.6678 - val_loss: 22.3936 - val_mae: 2.5280 - val_accuracy: 0.5305\n",
            "Epoch 15/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 24.1625 - mae: 2.6881 - accuracy: 0.6849 - val_loss: 17.9180 - val_mae: 1.7701 - val_accuracy: 0.6780\n",
            "Epoch 16/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 21.9813 - mae: 2.4648 - accuracy: 0.7040 - val_loss: 18.7849 - val_mae: 2.1616 - val_accuracy: 0.7135\n",
            "Epoch 17/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 22.1136 - mae: 2.5396 - accuracy: 0.7315 - val_loss: 16.6746 - val_mae: 1.6504 - val_accuracy: 0.7418\n",
            "Epoch 18/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 20.5075 - mae: 2.3883 - accuracy: 0.7326 - val_loss: 16.2904 - val_mae: 1.6413 - val_accuracy: 0.7390\n",
            "Epoch 19/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 19.8151 - mae: 2.3460 - accuracy: 0.7390 - val_loss: 14.0658 - val_mae: 1.2892 - val_accuracy: 0.7390\n",
            "Epoch 20/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 19.9272 - mae: 2.4046 - accuracy: 0.7349 - val_loss: 17.2999 - val_mae: 1.9952 - val_accuracy: 0.7163\n",
            "Epoch 21/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 19.6194 - mae: 2.3939 - accuracy: 0.7450 - val_loss: 13.3679 - val_mae: 1.1956 - val_accuracy: 0.7149\n",
            "Epoch 22/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 19.3758 - mae: 2.3546 - accuracy: 0.7317 - val_loss: 16.4326 - val_mae: 1.8865 - val_accuracy: 0.5348\n",
            "Epoch 23/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 20.6425 - mae: 2.4234 - accuracy: 0.7445 - val_loss: 36.8650 - val_mae: 4.4656 - val_accuracy: 0.5447\n",
            "Epoch 24/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 24.1658 - mae: 2.9515 - accuracy: 0.7138 - val_loss: 16.9622 - val_mae: 2.1645 - val_accuracy: 0.7390\n",
            "Epoch 25/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 18.6829 - mae: 2.3697 - accuracy: 0.7246 - val_loss: 13.5131 - val_mae: 1.5862 - val_accuracy: 0.7411\n",
            "Epoch 26/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 17.3296 - mae: 2.2483 - accuracy: 0.7569 - val_loss: 12.4223 - val_mae: 1.3892 - val_accuracy: 0.7759\n",
            "Epoch 27/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 16.5654 - mae: 2.2049 - accuracy: 0.7643 - val_loss: 18.4267 - val_mae: 2.5476 - val_accuracy: 0.7773\n",
            "Epoch 28/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 16.6560 - mae: 2.2314 - accuracy: 0.7695 - val_loss: 22.5793 - val_mae: 3.0660 - val_accuracy: 0.7489\n",
            "Epoch 29/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 18.3983 - mae: 2.4034 - accuracy: 0.7854 - val_loss: 21.4278 - val_mae: 2.9845 - val_accuracy: 0.7610\n",
            "Epoch 30/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 17.5805 - mae: 2.4085 - accuracy: 0.7750 - val_loss: 34.6729 - val_mae: 4.4802 - val_accuracy: 0.7482\n",
            "Epoch 31/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 18.6883 - mae: 2.5625 - accuracy: 0.7624 - val_loss: 10.9589 - val_mae: 1.2462 - val_accuracy: 0.7411\n",
            "Epoch 32/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 15.3410 - mae: 2.1568 - accuracy: 0.7748 - val_loss: 11.4989 - val_mae: 1.5529 - val_accuracy: 0.7582\n",
            "Epoch 33/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 14.9835 - mae: 2.1481 - accuracy: 0.7750 - val_loss: 10.7501 - val_mae: 1.3164 - val_accuracy: 0.7227\n",
            "Epoch 34/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 14.6916 - mae: 2.0858 - accuracy: 0.7755 - val_loss: 12.2765 - val_mae: 1.7594 - val_accuracy: 0.7596\n",
            "Epoch 35/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 14.9412 - mae: 2.1479 - accuracy: 0.7666 - val_loss: 11.0973 - val_mae: 1.5273 - val_accuracy: 0.7163\n",
            "Epoch 36/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 14.5392 - mae: 2.1463 - accuracy: 0.7771 - val_loss: 9.8504 - val_mae: 1.2780 - val_accuracy: 0.7440\n",
            "Epoch 37/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 13.9091 - mae: 2.0658 - accuracy: 0.7773 - val_loss: 10.3784 - val_mae: 1.4877 - val_accuracy: 0.7184\n",
            "Epoch 38/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 13.9878 - mae: 2.0765 - accuracy: 0.7790 - val_loss: 10.7113 - val_mae: 1.4124 - val_accuracy: 0.7170\n",
            "Epoch 39/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 13.6378 - mae: 2.0798 - accuracy: 0.7762 - val_loss: 10.3341 - val_mae: 1.3726 - val_accuracy: 0.6986\n",
            "Epoch 40/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 12.9288 - mae: 1.9799 - accuracy: 0.7842 - val_loss: 18.1936 - val_mae: 3.0360 - val_accuracy: 0.7589\n",
            "Epoch 41/400\n",
            "23/23 [==============================] - 10s 413ms/step - loss: 13.8290 - mae: 2.1629 - accuracy: 0.7865 - val_loss: 9.5260 - val_mae: 1.3885 - val_accuracy: 0.7667\n",
            "Epoch 42/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 12.1166 - mae: 1.9208 - accuracy: 0.7945 - val_loss: 8.9291 - val_mae: 1.1466 - val_accuracy: 0.7319\n",
            "Epoch 43/400\n",
            "23/23 [==============================] - 9s 372ms/step - loss: 12.0754 - mae: 1.9171 - accuracy: 0.7961 - val_loss: 14.5728 - val_mae: 2.4453 - val_accuracy: 0.7270\n",
            "Epoch 44/400\n",
            "23/23 [==============================] - 9s 372ms/step - loss: 14.0618 - mae: 2.2221 - accuracy: 0.7966 - val_loss: 12.6623 - val_mae: 2.0351 - val_accuracy: 0.7610\n",
            "Epoch 45/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 14.3743 - mae: 2.2922 - accuracy: 0.7973 - val_loss: 8.6463 - val_mae: 1.1239 - val_accuracy: 0.7475\n",
            "Epoch 46/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 13.2525 - mae: 2.0694 - accuracy: 0.7900 - val_loss: 8.7734 - val_mae: 1.2186 - val_accuracy: 0.7624\n",
            "Epoch 47/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 12.0102 - mae: 1.9247 - accuracy: 0.7920 - val_loss: 11.2067 - val_mae: 1.7155 - val_accuracy: 0.7312\n",
            "Epoch 48/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 12.0727 - mae: 1.9758 - accuracy: 0.7796 - val_loss: 12.6488 - val_mae: 2.1784 - val_accuracy: 0.7121\n",
            "Epoch 49/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 12.0614 - mae: 1.9983 - accuracy: 0.7906 - val_loss: 8.4853 - val_mae: 1.3199 - val_accuracy: 0.7298\n",
            "Epoch 50/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 11.4408 - mae: 1.9103 - accuracy: 0.7939 - val_loss: 8.1863 - val_mae: 1.2379 - val_accuracy: 0.7312\n",
            "Epoch 51/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 11.0089 - mae: 1.8746 - accuracy: 0.8005 - val_loss: 8.1353 - val_mae: 1.1668 - val_accuracy: 0.7553\n",
            "Epoch 52/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 11.1119 - mae: 1.9181 - accuracy: 0.7945 - val_loss: 12.0994 - val_mae: 1.8917 - val_accuracy: 0.6887\n",
            "Epoch 53/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 10.6955 - mae: 1.8706 - accuracy: 0.7945 - val_loss: 7.6037 - val_mae: 1.0562 - val_accuracy: 0.7426\n",
            "Epoch 54/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 10.5974 - mae: 1.8383 - accuracy: 0.7984 - val_loss: 17.9116 - val_mae: 3.1760 - val_accuracy: 0.7518\n",
            "Epoch 55/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 11.8298 - mae: 2.0661 - accuracy: 0.8039 - val_loss: 7.7530 - val_mae: 1.2165 - val_accuracy: 0.7355\n",
            "Epoch 56/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 10.4816 - mae: 1.8583 - accuracy: 0.8019 - val_loss: 10.3909 - val_mae: 1.8732 - val_accuracy: 0.7319\n",
            "Epoch 57/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 11.3637 - mae: 2.0055 - accuracy: 0.8037 - val_loss: 10.5798 - val_mae: 1.9029 - val_accuracy: 0.7624\n",
            "Epoch 58/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 10.4185 - mae: 1.8371 - accuracy: 0.8081 - val_loss: 10.1959 - val_mae: 1.9118 - val_accuracy: 0.7511\n",
            "Epoch 59/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 10.5008 - mae: 1.9087 - accuracy: 0.8003 - val_loss: 8.6504 - val_mae: 1.3887 - val_accuracy: 0.7433\n",
            "Epoch 60/400\n",
            "23/23 [==============================] - 9s 372ms/step - loss: 9.8466 - mae: 1.8211 - accuracy: 0.8072 - val_loss: 6.9056 - val_mae: 1.0547 - val_accuracy: 0.7404\n",
            "Epoch 61/400\n",
            "23/23 [==============================] - 9s 372ms/step - loss: 9.8374 - mae: 1.8222 - accuracy: 0.8044 - val_loss: 6.9480 - val_mae: 1.2075 - val_accuracy: 0.7830\n",
            "Epoch 62/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 9.6025 - mae: 1.7725 - accuracy: 0.8129 - val_loss: 16.1452 - val_mae: 2.8014 - val_accuracy: 0.6936\n",
            "Epoch 63/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 11.1849 - mae: 2.0238 - accuracy: 0.7913 - val_loss: 17.2403 - val_mae: 3.1049 - val_accuracy: 0.7504\n",
            "Epoch 64/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 11.3011 - mae: 2.0550 - accuracy: 0.8053 - val_loss: 7.1988 - val_mae: 1.1870 - val_accuracy: 0.7532\n",
            "Epoch 65/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 9.4459 - mae: 1.7765 - accuracy: 0.8069 - val_loss: 10.2980 - val_mae: 1.8597 - val_accuracy: 0.7475\n",
            "Epoch 66/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 10.2857 - mae: 1.9315 - accuracy: 0.8172 - val_loss: 8.2965 - val_mae: 1.5491 - val_accuracy: 0.7660\n",
            "Epoch 67/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 9.1726 - mae: 1.7601 - accuracy: 0.8069 - val_loss: 8.2076 - val_mae: 1.6220 - val_accuracy: 0.7468\n",
            "Epoch 68/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 9.4533 - mae: 1.8212 - accuracy: 0.7978 - val_loss: 7.3497 - val_mae: 1.2012 - val_accuracy: 0.7454\n",
            "Epoch 69/400\n",
            "23/23 [==============================] - 9s 371ms/step - loss: 9.7130 - mae: 1.8348 - accuracy: 0.8156 - val_loss: 30.6681 - val_mae: 4.6144 - val_accuracy: 0.7574\n",
            "Epoch 70/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 13.1907 - mae: 2.3477 - accuracy: 0.8023 - val_loss: 11.7018 - val_mae: 1.9449 - val_accuracy: 0.7206\n",
            "Epoch 71/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 9.9838 - mae: 1.8968 - accuracy: 0.8012 - val_loss: 20.2639 - val_mae: 3.6186 - val_accuracy: 0.7787\n",
            "Epoch 72/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 9.2713 - mae: 1.8115 - accuracy: 0.8117 - val_loss: 19.9911 - val_mae: 3.5911 - val_accuracy: 0.7766\n",
            "Epoch 73/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 9.2859 - mae: 1.8355 - accuracy: 0.8205 - val_loss: 11.1011 - val_mae: 2.1594 - val_accuracy: 0.7539\n",
            "Epoch 74/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 9.0980 - mae: 1.8119 - accuracy: 0.8186 - val_loss: 8.9613 - val_mae: 1.6478 - val_accuracy: 0.7404\n",
            "Epoch 75/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 9.6161 - mae: 1.9131 - accuracy: 0.8181 - val_loss: 11.5618 - val_mae: 2.3847 - val_accuracy: 0.7681\n",
            "Epoch 76/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 8.5775 - mae: 1.7319 - accuracy: 0.8223 - val_loss: 9.3888 - val_mae: 1.8594 - val_accuracy: 0.7610\n",
            "Epoch 77/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 9.2803 - mae: 1.8678 - accuracy: 0.8275 - val_loss: 8.0535 - val_mae: 1.7144 - val_accuracy: 0.7255\n",
            "Epoch 78/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 8.6365 - mae: 1.7898 - accuracy: 0.8253 - val_loss: 6.9865 - val_mae: 1.4732 - val_accuracy: 0.7723\n",
            "Epoch 79/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 8.1191 - mae: 1.6893 - accuracy: 0.8271 - val_loss: 6.9340 - val_mae: 1.4577 - val_accuracy: 0.7518\n",
            "Epoch 80/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.7087 - mae: 1.6239 - accuracy: 0.8255 - val_loss: 7.1725 - val_mae: 1.3629 - val_accuracy: 0.7518\n",
            "Epoch 81/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 8.4990 - mae: 1.7812 - accuracy: 0.8244 - val_loss: 8.9312 - val_mae: 1.7031 - val_accuracy: 0.7582\n",
            "Epoch 82/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 8.5623 - mae: 1.7401 - accuracy: 0.8365 - val_loss: 7.5323 - val_mae: 1.3436 - val_accuracy: 0.7695\n",
            "Epoch 83/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 8.2810 - mae: 1.7295 - accuracy: 0.8191 - val_loss: 5.5316 - val_mae: 0.9992 - val_accuracy: 0.7447\n",
            "Epoch 84/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.6651 - mae: 1.6348 - accuracy: 0.8259 - val_loss: 6.0013 - val_mae: 1.0160 - val_accuracy: 0.7759\n",
            "Epoch 85/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.6706 - mae: 1.6640 - accuracy: 0.8253 - val_loss: 9.5862 - val_mae: 2.1603 - val_accuracy: 0.7766\n",
            "Epoch 86/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.9253 - mae: 1.7263 - accuracy: 0.8273 - val_loss: 23.0409 - val_mae: 3.9213 - val_accuracy: 0.7567\n",
            "Epoch 87/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 9.4877 - mae: 1.9895 - accuracy: 0.8363 - val_loss: 8.8314 - val_mae: 1.8513 - val_accuracy: 0.7447\n",
            "Epoch 88/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.4907 - mae: 1.6444 - accuracy: 0.8269 - val_loss: 12.8302 - val_mae: 2.6829 - val_accuracy: 0.7511\n",
            "Epoch 89/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 7.7693 - mae: 1.6812 - accuracy: 0.8298 - val_loss: 6.7687 - val_mae: 1.4200 - val_accuracy: 0.7780\n",
            "Epoch 90/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 7.2703 - mae: 1.6003 - accuracy: 0.8356 - val_loss: 6.7841 - val_mae: 1.2088 - val_accuracy: 0.7645\n",
            "Epoch 91/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 7.5480 - mae: 1.6407 - accuracy: 0.8356 - val_loss: 6.0462 - val_mae: 1.1664 - val_accuracy: 0.7780\n",
            "Epoch 92/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.7744 - mae: 1.7039 - accuracy: 0.8278 - val_loss: 5.5269 - val_mae: 1.1083 - val_accuracy: 0.7645\n",
            "Epoch 93/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.2360 - mae: 1.6174 - accuracy: 0.8356 - val_loss: 9.5539 - val_mae: 2.1561 - val_accuracy: 0.7638\n",
            "Epoch 94/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 7.6346 - mae: 1.7023 - accuracy: 0.8324 - val_loss: 5.9708 - val_mae: 1.0811 - val_accuracy: 0.7667\n",
            "Epoch 95/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 7.2111 - mae: 1.6402 - accuracy: 0.8345 - val_loss: 11.6734 - val_mae: 2.4795 - val_accuracy: 0.7326\n",
            "Epoch 96/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.3025 - mae: 1.6422 - accuracy: 0.8354 - val_loss: 8.3327 - val_mae: 1.8774 - val_accuracy: 0.7582\n",
            "Epoch 97/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.0942 - mae: 1.6033 - accuracy: 0.8356 - val_loss: 6.1885 - val_mae: 1.4171 - val_accuracy: 0.7262\n",
            "Epoch 98/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.1181 - mae: 1.5969 - accuracy: 0.8370 - val_loss: 6.9898 - val_mae: 1.6331 - val_accuracy: 0.7255\n",
            "Epoch 99/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 7.1121 - mae: 1.6137 - accuracy: 0.8282 - val_loss: 9.3824 - val_mae: 1.9716 - val_accuracy: 0.7723\n",
            "Epoch 100/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.6710 - mae: 1.7530 - accuracy: 0.8337 - val_loss: 6.4592 - val_mae: 1.4685 - val_accuracy: 0.7496\n",
            "Epoch 101/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.7472 - mae: 1.5885 - accuracy: 0.8344 - val_loss: 5.5480 - val_mae: 1.0205 - val_accuracy: 0.7574\n",
            "Epoch 102/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.8462 - mae: 1.5920 - accuracy: 0.8399 - val_loss: 5.5298 - val_mae: 1.0012 - val_accuracy: 0.7816\n",
            "Epoch 103/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.7220 - mae: 1.5840 - accuracy: 0.8329 - val_loss: 12.0559 - val_mae: 2.4821 - val_accuracy: 0.7574\n",
            "Epoch 104/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.3605 - mae: 1.7116 - accuracy: 0.8340 - val_loss: 8.9827 - val_mae: 1.9715 - val_accuracy: 0.7681\n",
            "Epoch 105/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.3564 - mae: 1.6574 - accuracy: 0.8388 - val_loss: 4.7248 - val_mae: 0.9824 - val_accuracy: 0.8071\n",
            "Epoch 106/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.8389 - mae: 1.5765 - accuracy: 0.8317 - val_loss: 7.1589 - val_mae: 1.4657 - val_accuracy: 0.7227\n",
            "Epoch 107/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 7.4850 - mae: 1.7389 - accuracy: 0.8306 - val_loss: 9.4256 - val_mae: 1.9610 - val_accuracy: 0.7404\n",
            "Epoch 108/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 8.5103 - mae: 1.9274 - accuracy: 0.8374 - val_loss: 7.1497 - val_mae: 1.6781 - val_accuracy: 0.7816\n",
            "Epoch 109/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 8.0880 - mae: 1.8401 - accuracy: 0.8434 - val_loss: 7.8845 - val_mae: 1.8780 - val_accuracy: 0.8000\n",
            "Epoch 110/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 8.9740 - mae: 1.7154 - accuracy: 0.8443 - val_loss: 41.2704 - val_mae: 5.4917 - val_accuracy: 0.7078\n",
            "Epoch 111/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 13.7934 - mae: 2.4795 - accuracy: 0.7666 - val_loss: 12.2239 - val_mae: 2.2150 - val_accuracy: 0.7128\n",
            "Epoch 112/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 9.4315 - mae: 1.9060 - accuracy: 0.7833 - val_loss: 9.2815 - val_mae: 1.8684 - val_accuracy: 0.7348\n",
            "Epoch 113/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 7.8425 - mae: 1.7186 - accuracy: 0.8106 - val_loss: 6.2091 - val_mae: 1.1820 - val_accuracy: 0.7525\n",
            "Epoch 114/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.9540 - mae: 1.6204 - accuracy: 0.8195 - val_loss: 4.9688 - val_mae: 0.9025 - val_accuracy: 0.7723\n",
            "Epoch 115/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.1070 - mae: 1.6280 - accuracy: 0.8202 - val_loss: 8.8580 - val_mae: 1.6340 - val_accuracy: 0.7390\n",
            "Epoch 116/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.3437 - mae: 1.6960 - accuracy: 0.8202 - val_loss: 5.0921 - val_mae: 1.0389 - val_accuracy: 0.7830\n",
            "Epoch 117/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.4784 - mae: 1.5696 - accuracy: 0.8253 - val_loss: 5.8795 - val_mae: 1.0585 - val_accuracy: 0.7560\n",
            "Epoch 118/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 6.6605 - mae: 1.6202 - accuracy: 0.8329 - val_loss: 9.6756 - val_mae: 2.1367 - val_accuracy: 0.7667\n",
            "Epoch 119/400\n",
            "23/23 [==============================] - 9s 372ms/step - loss: 7.1155 - mae: 1.7118 - accuracy: 0.8423 - val_loss: 9.4313 - val_mae: 2.1890 - val_accuracy: 0.7496\n",
            "Epoch 120/400\n",
            "23/23 [==============================] - 9s 372ms/step - loss: 6.2496 - mae: 1.5533 - accuracy: 0.8432 - val_loss: 5.6598 - val_mae: 1.2274 - val_accuracy: 0.7922\n",
            "Epoch 121/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.4232 - mae: 1.6018 - accuracy: 0.8397 - val_loss: 4.7769 - val_mae: 0.9704 - val_accuracy: 0.7929\n",
            "Epoch 122/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.3051 - mae: 1.5823 - accuracy: 0.8431 - val_loss: 5.8814 - val_mae: 1.3319 - val_accuracy: 0.7908\n",
            "Epoch 123/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 6.2437 - mae: 1.5383 - accuracy: 0.8493 - val_loss: 9.6426 - val_mae: 2.0949 - val_accuracy: 0.7475\n",
            "Epoch 124/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 6.7528 - mae: 1.6553 - accuracy: 0.8532 - val_loss: 18.2851 - val_mae: 3.4859 - val_accuracy: 0.7277\n",
            "Epoch 125/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 8.7246 - mae: 1.9882 - accuracy: 0.8473 - val_loss: 8.8846 - val_mae: 2.1088 - val_accuracy: 0.7482\n",
            "Epoch 126/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.0077 - mae: 1.6903 - accuracy: 0.8447 - val_loss: 5.4968 - val_mae: 1.0015 - val_accuracy: 0.7858\n",
            "Epoch 127/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 7.0722 - mae: 1.7303 - accuracy: 0.8415 - val_loss: 4.2311 - val_mae: 0.8223 - val_accuracy: 0.7965\n",
            "Epoch 128/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.9516 - mae: 1.5137 - accuracy: 0.8448 - val_loss: 4.9835 - val_mae: 1.2573 - val_accuracy: 0.7759\n",
            "Epoch 129/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.7220 - mae: 1.5027 - accuracy: 0.8567 - val_loss: 12.2028 - val_mae: 2.7672 - val_accuracy: 0.7844\n",
            "Epoch 130/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 6.9343 - mae: 1.7300 - accuracy: 0.8486 - val_loss: 4.3460 - val_mae: 0.9074 - val_accuracy: 0.7667\n",
            "Epoch 131/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.7804 - mae: 1.5012 - accuracy: 0.8470 - val_loss: 5.1846 - val_mae: 1.2163 - val_accuracy: 0.7645\n",
            "Epoch 132/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.7088 - mae: 1.4849 - accuracy: 0.8484 - val_loss: 5.8332 - val_mae: 1.5283 - val_accuracy: 0.7723\n",
            "Epoch 133/400\n",
            "23/23 [==============================] - 9s 372ms/step - loss: 5.6055 - mae: 1.4897 - accuracy: 0.8562 - val_loss: 5.0712 - val_mae: 1.2246 - val_accuracy: 0.8128\n",
            "Epoch 134/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.7032 - mae: 1.5090 - accuracy: 0.8565 - val_loss: 7.9654 - val_mae: 2.0796 - val_accuracy: 0.7936\n",
            "Epoch 135/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.7232 - mae: 1.4949 - accuracy: 0.8512 - val_loss: 6.8535 - val_mae: 1.4605 - val_accuracy: 0.7418\n",
            "Epoch 136/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 6.3458 - mae: 1.5979 - accuracy: 0.8225 - val_loss: 9.4900 - val_mae: 2.3442 - val_accuracy: 0.7404\n",
            "Epoch 137/400\n",
            "23/23 [==============================] - 9s 372ms/step - loss: 6.7068 - mae: 1.6672 - accuracy: 0.8283 - val_loss: 9.4603 - val_mae: 2.3063 - val_accuracy: 0.7950\n",
            "Epoch 138/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 6.1944 - mae: 1.5896 - accuracy: 0.8431 - val_loss: 8.1525 - val_mae: 1.5952 - val_accuracy: 0.7723\n",
            "Epoch 139/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.1733 - mae: 1.5491 - accuracy: 0.8503 - val_loss: 8.8420 - val_mae: 2.0674 - val_accuracy: 0.7993\n",
            "Epoch 140/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 7.6040 - mae: 1.8374 - accuracy: 0.8388 - val_loss: 16.6982 - val_mae: 3.3963 - val_accuracy: 0.8170\n",
            "Epoch 141/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 7.5112 - mae: 1.8127 - accuracy: 0.8241 - val_loss: 8.6888 - val_mae: 1.6324 - val_accuracy: 0.7106\n",
            "Epoch 142/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.7729 - mae: 1.5123 - accuracy: 0.8447 - val_loss: 5.8262 - val_mae: 1.1021 - val_accuracy: 0.7348\n",
            "Epoch 143/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.4407 - mae: 1.4657 - accuracy: 0.8532 - val_loss: 4.3944 - val_mae: 1.0194 - val_accuracy: 0.7908\n",
            "Epoch 144/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.0592 - mae: 1.5784 - accuracy: 0.8509 - val_loss: 8.1053 - val_mae: 2.1079 - val_accuracy: 0.7567\n",
            "Epoch 145/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.1469 - mae: 1.7099 - accuracy: 0.8030 - val_loss: 6.7677 - val_mae: 1.3551 - val_accuracy: 0.7610\n",
            "Epoch 146/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.5875 - mae: 1.6548 - accuracy: 0.8207 - val_loss: 7.3088 - val_mae: 1.4240 - val_accuracy: 0.7071\n",
            "Epoch 147/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.2793 - mae: 1.5828 - accuracy: 0.8344 - val_loss: 15.5143 - val_mae: 2.8494 - val_accuracy: 0.6965\n",
            "Epoch 148/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 6.8468 - mae: 1.7157 - accuracy: 0.8305 - val_loss: 5.1336 - val_mae: 1.0194 - val_accuracy: 0.7780\n",
            "Epoch 149/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.9385 - mae: 1.5542 - accuracy: 0.8384 - val_loss: 5.2207 - val_mae: 1.0986 - val_accuracy: 0.7596\n",
            "Epoch 150/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.4149 - mae: 1.4646 - accuracy: 0.8443 - val_loss: 5.3848 - val_mae: 1.3347 - val_accuracy: 0.7496\n",
            "Epoch 151/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.3603 - mae: 1.4644 - accuracy: 0.8413 - val_loss: 8.9433 - val_mae: 2.3286 - val_accuracy: 0.7397\n",
            "Epoch 152/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.4588 - mae: 1.6815 - accuracy: 0.8306 - val_loss: 6.4840 - val_mae: 1.4745 - val_accuracy: 0.7773\n",
            "Epoch 153/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.8743 - mae: 1.5652 - accuracy: 0.8494 - val_loss: 6.1960 - val_mae: 1.5115 - val_accuracy: 0.7681\n",
            "Epoch 154/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.4011 - mae: 1.4784 - accuracy: 0.8473 - val_loss: 6.3812 - val_mae: 1.6858 - val_accuracy: 0.7943\n",
            "Epoch 155/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.3376 - mae: 1.4766 - accuracy: 0.8533 - val_loss: 5.2521 - val_mae: 1.3105 - val_accuracy: 0.7887\n",
            "Epoch 156/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.9584 - mae: 1.5290 - accuracy: 0.8533 - val_loss: 5.8087 - val_mae: 1.2286 - val_accuracy: 0.7986\n",
            "Epoch 157/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 6.5488 - mae: 1.6598 - accuracy: 0.8395 - val_loss: 4.8232 - val_mae: 1.0442 - val_accuracy: 0.7773\n",
            "Epoch 158/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.5016 - mae: 1.4870 - accuracy: 0.8564 - val_loss: 3.8663 - val_mae: 0.8079 - val_accuracy: 0.7972\n",
            "Epoch 159/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.6857 - mae: 1.5150 - accuracy: 0.8528 - val_loss: 4.5118 - val_mae: 0.9737 - val_accuracy: 0.7965\n",
            "Epoch 160/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.2647 - mae: 1.4680 - accuracy: 0.8521 - val_loss: 4.1283 - val_mae: 0.9916 - val_accuracy: 0.7674\n",
            "Epoch 161/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.9937 - mae: 1.4233 - accuracy: 0.8558 - val_loss: 6.7185 - val_mae: 1.7929 - val_accuracy: 0.7993\n",
            "Epoch 162/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.3505 - mae: 1.4824 - accuracy: 0.8572 - val_loss: 4.6126 - val_mae: 1.0070 - val_accuracy: 0.7390\n",
            "Epoch 163/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.2976 - mae: 1.4551 - accuracy: 0.8565 - val_loss: 4.5657 - val_mae: 1.0974 - val_accuracy: 0.8035\n",
            "Epoch 164/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.5848 - mae: 1.5119 - accuracy: 0.8578 - val_loss: 4.8898 - val_mae: 1.3104 - val_accuracy: 0.7809\n",
            "Epoch 165/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.1102 - mae: 1.4357 - accuracy: 0.8580 - val_loss: 4.1328 - val_mae: 1.1123 - val_accuracy: 0.8149\n",
            "Epoch 166/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.0234 - mae: 1.4195 - accuracy: 0.8599 - val_loss: 10.0993 - val_mae: 2.4324 - val_accuracy: 0.7901\n",
            "Epoch 167/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 6.8070 - mae: 1.7836 - accuracy: 0.8645 - val_loss: 3.8562 - val_mae: 0.8435 - val_accuracy: 0.7787\n",
            "Epoch 168/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.9114 - mae: 1.4072 - accuracy: 0.8603 - val_loss: 3.6747 - val_mae: 0.8637 - val_accuracy: 0.7986\n",
            "Epoch 169/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.8299 - mae: 1.3802 - accuracy: 0.8532 - val_loss: 3.8636 - val_mae: 0.8286 - val_accuracy: 0.7908\n",
            "Epoch 170/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.2586 - mae: 1.4854 - accuracy: 0.8636 - val_loss: 3.7709 - val_mae: 0.8004 - val_accuracy: 0.8014\n",
            "Epoch 171/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.4096 - mae: 1.4914 - accuracy: 0.8537 - val_loss: 15.4923 - val_mae: 3.1778 - val_accuracy: 0.7809\n",
            "Epoch 172/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.6049 - mae: 1.7073 - accuracy: 0.8564 - val_loss: 19.4514 - val_mae: 3.7980 - val_accuracy: 0.7326\n",
            "Epoch 173/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.1660 - mae: 1.6684 - accuracy: 0.8585 - val_loss: 5.7922 - val_mae: 1.5091 - val_accuracy: 0.7809\n",
            "Epoch 174/400\n",
            "23/23 [==============================] - 9s 372ms/step - loss: 5.6148 - mae: 1.5386 - accuracy: 0.8626 - val_loss: 21.2055 - val_mae: 4.0039 - val_accuracy: 0.8028\n",
            "Epoch 175/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 7.1769 - mae: 1.8350 - accuracy: 0.8585 - val_loss: 3.9477 - val_mae: 0.8684 - val_accuracy: 0.7950\n",
            "Epoch 176/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.9440 - mae: 1.4263 - accuracy: 0.8631 - val_loss: 3.7760 - val_mae: 0.9427 - val_accuracy: 0.8142\n",
            "Epoch 177/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 4.9405 - mae: 1.4176 - accuracy: 0.8613 - val_loss: 3.6246 - val_mae: 0.7405 - val_accuracy: 0.7887\n",
            "Epoch 178/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.0120 - mae: 1.4398 - accuracy: 0.8587 - val_loss: 4.0129 - val_mae: 0.8934 - val_accuracy: 0.8071\n",
            "Epoch 179/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 4.9751 - mae: 1.4582 - accuracy: 0.8624 - val_loss: 4.2255 - val_mae: 0.8706 - val_accuracy: 0.7340\n",
            "Epoch 180/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 5.4284 - mae: 1.5448 - accuracy: 0.8663 - val_loss: 3.8997 - val_mae: 0.8147 - val_accuracy: 0.7752\n",
            "Epoch 181/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.7423 - mae: 1.3756 - accuracy: 0.8711 - val_loss: 6.2140 - val_mae: 1.7605 - val_accuracy: 0.8071\n",
            "Epoch 182/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 5.3660 - mae: 1.5161 - accuracy: 0.8619 - val_loss: 4.8129 - val_mae: 0.9680 - val_accuracy: 0.7745\n",
            "Epoch 183/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.5351 - mae: 1.5061 - accuracy: 0.8377 - val_loss: 4.6238 - val_mae: 1.2662 - val_accuracy: 0.8035\n",
            "Epoch 184/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.5419 - mae: 1.5233 - accuracy: 0.8569 - val_loss: 7.8613 - val_mae: 2.0014 - val_accuracy: 0.7915\n",
            "Epoch 185/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.4077 - mae: 1.6756 - accuracy: 0.8558 - val_loss: 5.3373 - val_mae: 1.5083 - val_accuracy: 0.8014\n",
            "Epoch 186/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.2517 - mae: 1.5088 - accuracy: 0.8663 - val_loss: 3.7186 - val_mae: 0.8364 - val_accuracy: 0.8050\n",
            "Epoch 187/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.5565 - mae: 1.3646 - accuracy: 0.8647 - val_loss: 3.7637 - val_mae: 0.8823 - val_accuracy: 0.7936\n",
            "Epoch 188/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.5961 - mae: 1.3771 - accuracy: 0.8592 - val_loss: 3.3753 - val_mae: 0.7485 - val_accuracy: 0.7972\n",
            "Epoch 189/400\n",
            "23/23 [==============================] - 9s 372ms/step - loss: 4.6902 - mae: 1.3558 - accuracy: 0.8736 - val_loss: 7.6068 - val_mae: 1.9526 - val_accuracy: 0.8050\n",
            "Epoch 190/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.8737 - mae: 1.6216 - accuracy: 0.8682 - val_loss: 5.0793 - val_mae: 1.3310 - val_accuracy: 0.7766\n",
            "Epoch 191/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.7126 - mae: 1.6050 - accuracy: 0.8682 - val_loss: 10.1776 - val_mae: 2.5518 - val_accuracy: 0.7844\n",
            "Epoch 192/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.9456 - mae: 1.4603 - accuracy: 0.8626 - val_loss: 3.3436 - val_mae: 0.8399 - val_accuracy: 0.7809\n",
            "Epoch 193/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.5216 - mae: 1.3674 - accuracy: 0.8707 - val_loss: 3.9857 - val_mae: 1.1523 - val_accuracy: 0.7702\n",
            "Epoch 194/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.5207 - mae: 1.3638 - accuracy: 0.8684 - val_loss: 6.4882 - val_mae: 1.8597 - val_accuracy: 0.8028\n",
            "Epoch 195/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.7864 - mae: 1.3961 - accuracy: 0.8748 - val_loss: 3.5884 - val_mae: 0.7909 - val_accuracy: 0.8028\n",
            "Epoch 196/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.1642 - mae: 1.4865 - accuracy: 0.8610 - val_loss: 7.0255 - val_mae: 1.9806 - val_accuracy: 0.8035\n",
            "Epoch 197/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 6.5077 - mae: 1.7060 - accuracy: 0.8356 - val_loss: 13.9398 - val_mae: 2.9722 - val_accuracy: 0.7326\n",
            "Epoch 198/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 7.7919 - mae: 1.8792 - accuracy: 0.8182 - val_loss: 4.6725 - val_mae: 0.9862 - val_accuracy: 0.7589\n",
            "Epoch 199/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.4093 - mae: 1.5008 - accuracy: 0.8477 - val_loss: 5.3276 - val_mae: 1.0590 - val_accuracy: 0.7688\n",
            "Epoch 200/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.9929 - mae: 1.4349 - accuracy: 0.8569 - val_loss: 4.9042 - val_mae: 1.1497 - val_accuracy: 0.7589\n",
            "Epoch 201/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.9150 - mae: 1.4394 - accuracy: 0.8606 - val_loss: 6.8513 - val_mae: 1.7381 - val_accuracy: 0.7560\n",
            "Epoch 202/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 5.2453 - mae: 1.4284 - accuracy: 0.8663 - val_loss: 4.6233 - val_mae: 1.0686 - val_accuracy: 0.7908\n",
            "Epoch 203/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.4512 - mae: 1.5090 - accuracy: 0.8471 - val_loss: 4.2026 - val_mae: 1.0130 - val_accuracy: 0.7738\n",
            "Epoch 204/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 4.7091 - mae: 1.3507 - accuracy: 0.8603 - val_loss: 5.1824 - val_mae: 1.4326 - val_accuracy: 0.7972\n",
            "Epoch 205/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.8916 - mae: 1.4323 - accuracy: 0.8603 - val_loss: 6.7032 - val_mae: 1.8864 - val_accuracy: 0.7894\n",
            "Epoch 206/400\n",
            "23/23 [==============================] - 9s 372ms/step - loss: 4.7809 - mae: 1.4124 - accuracy: 0.8704 - val_loss: 4.4700 - val_mae: 1.1520 - val_accuracy: 0.8035\n",
            "Epoch 207/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.2851 - mae: 1.4814 - accuracy: 0.8619 - val_loss: 5.4477 - val_mae: 1.5714 - val_accuracy: 0.7695\n",
            "Epoch 208/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.7894 - mae: 1.4200 - accuracy: 0.8716 - val_loss: 3.6576 - val_mae: 0.9582 - val_accuracy: 0.8085\n",
            "Epoch 209/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.5480 - mae: 1.3671 - accuracy: 0.8661 - val_loss: 17.6649 - val_mae: 3.5253 - val_accuracy: 0.7972\n",
            "Epoch 210/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 6.7241 - mae: 1.7948 - accuracy: 0.8595 - val_loss: 3.7240 - val_mae: 0.8457 - val_accuracy: 0.7872\n",
            "Epoch 211/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.7705 - mae: 1.4213 - accuracy: 0.8737 - val_loss: 3.7399 - val_mae: 0.8116 - val_accuracy: 0.8028\n",
            "Epoch 212/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.4884 - mae: 1.3693 - accuracy: 0.8720 - val_loss: 3.6985 - val_mae: 0.8244 - val_accuracy: 0.8085\n",
            "Epoch 213/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.6990 - mae: 1.4030 - accuracy: 0.8720 - val_loss: 4.6301 - val_mae: 1.3303 - val_accuracy: 0.7879\n",
            "Epoch 214/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 6.6548 - mae: 1.7580 - accuracy: 0.8400 - val_loss: 5.4791 - val_mae: 1.4508 - val_accuracy: 0.7858\n",
            "Epoch 215/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.1152 - mae: 1.4901 - accuracy: 0.8635 - val_loss: 8.8805 - val_mae: 2.3188 - val_accuracy: 0.7738\n",
            "Epoch 216/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 5.6156 - mae: 1.5834 - accuracy: 0.8684 - val_loss: 4.3217 - val_mae: 1.0376 - val_accuracy: 0.8021\n",
            "Epoch 217/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.7338 - mae: 1.4106 - accuracy: 0.8716 - val_loss: 5.8677 - val_mae: 1.5051 - val_accuracy: 0.7787\n",
            "Epoch 218/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.7729 - mae: 1.4120 - accuracy: 0.8730 - val_loss: 6.4321 - val_mae: 1.6683 - val_accuracy: 0.7922\n",
            "Epoch 219/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.5151 - mae: 1.5749 - accuracy: 0.8654 - val_loss: 11.1502 - val_mae: 2.5454 - val_accuracy: 0.8028\n",
            "Epoch 220/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.4924 - mae: 1.5739 - accuracy: 0.8682 - val_loss: 5.2731 - val_mae: 1.2184 - val_accuracy: 0.7979\n",
            "Epoch 221/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 6.5367 - mae: 1.4387 - accuracy: 0.8714 - val_loss: 6.5596 - val_mae: 1.6037 - val_accuracy: 0.7879\n",
            "Epoch 222/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 7.8791 - mae: 1.8070 - accuracy: 0.8310 - val_loss: 7.4546 - val_mae: 1.4968 - val_accuracy: 0.4979\n",
            "Epoch 223/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 6.2573 - mae: 1.5047 - accuracy: 0.8353 - val_loss: 5.0113 - val_mae: 1.0412 - val_accuracy: 0.8064\n",
            "Epoch 224/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.6360 - mae: 1.4544 - accuracy: 0.8562 - val_loss: 6.7811 - val_mae: 1.4969 - val_accuracy: 0.7872\n",
            "Epoch 225/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 6.2674 - mae: 1.6144 - accuracy: 0.8610 - val_loss: 5.8687 - val_mae: 1.4847 - val_accuracy: 0.7936\n",
            "Epoch 226/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.2028 - mae: 1.4221 - accuracy: 0.8682 - val_loss: 3.8599 - val_mae: 0.7875 - val_accuracy: 0.8014\n",
            "Epoch 227/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.1834 - mae: 1.4433 - accuracy: 0.8635 - val_loss: 7.1131 - val_mae: 1.9972 - val_accuracy: 0.7759\n",
            "Epoch 228/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.1904 - mae: 1.4757 - accuracy: 0.8682 - val_loss: 5.0729 - val_mae: 1.3776 - val_accuracy: 0.7837\n",
            "Epoch 229/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.9891 - mae: 1.4086 - accuracy: 0.8695 - val_loss: 5.8303 - val_mae: 1.4430 - val_accuracy: 0.7957\n",
            "Epoch 230/400\n",
            "23/23 [==============================] - 9s 372ms/step - loss: 5.3698 - mae: 1.5055 - accuracy: 0.8328 - val_loss: 7.4729 - val_mae: 2.0281 - val_accuracy: 0.7801\n",
            "Epoch 231/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.0029 - mae: 1.4622 - accuracy: 0.8629 - val_loss: 5.5830 - val_mae: 1.5362 - val_accuracy: 0.7716\n",
            "Epoch 232/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.7407 - mae: 1.4133 - accuracy: 0.8727 - val_loss: 4.3595 - val_mae: 0.8972 - val_accuracy: 0.7411\n",
            "Epoch 233/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.3858 - mae: 1.3397 - accuracy: 0.8755 - val_loss: 4.4160 - val_mae: 1.2176 - val_accuracy: 0.7454\n",
            "Epoch 234/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.4614 - mae: 1.3563 - accuracy: 0.8720 - val_loss: 9.2004 - val_mae: 2.4084 - val_accuracy: 0.7844\n",
            "Epoch 235/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.0062 - mae: 1.4788 - accuracy: 0.8750 - val_loss: 4.3787 - val_mae: 1.0618 - val_accuracy: 0.7638\n",
            "Epoch 236/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.0750 - mae: 1.4597 - accuracy: 0.8711 - val_loss: 5.1367 - val_mae: 1.4302 - val_accuracy: 0.7589\n",
            "Epoch 237/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.6228 - mae: 1.3875 - accuracy: 0.8650 - val_loss: 9.2832 - val_mae: 2.3788 - val_accuracy: 0.7957\n",
            "Epoch 238/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 5.2647 - mae: 1.5592 - accuracy: 0.8720 - val_loss: 3.7643 - val_mae: 1.0661 - val_accuracy: 0.7362\n",
            "Epoch 239/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.2741 - mae: 1.3251 - accuracy: 0.8693 - val_loss: 3.9156 - val_mae: 0.9832 - val_accuracy: 0.7404\n",
            "Epoch 240/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.3401 - mae: 1.3687 - accuracy: 0.8718 - val_loss: 3.2058 - val_mae: 0.7517 - val_accuracy: 0.7780\n",
            "Epoch 241/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.1716 - mae: 1.3241 - accuracy: 0.8736 - val_loss: 3.7365 - val_mae: 1.0772 - val_accuracy: 0.7872\n",
            "Epoch 242/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.2649 - mae: 1.3363 - accuracy: 0.8822 - val_loss: 3.9352 - val_mae: 1.0203 - val_accuracy: 0.8064\n",
            "Epoch 243/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.5858 - mae: 1.4154 - accuracy: 0.8759 - val_loss: 8.3034 - val_mae: 2.2986 - val_accuracy: 0.8021\n",
            "Epoch 244/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.3418 - mae: 1.3702 - accuracy: 0.8876 - val_loss: 3.8721 - val_mae: 1.1801 - val_accuracy: 0.7830\n",
            "Epoch 245/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.3323 - mae: 1.3661 - accuracy: 0.8764 - val_loss: 6.4978 - val_mae: 1.7895 - val_accuracy: 0.7809\n",
            "Epoch 246/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.9766 - mae: 1.5158 - accuracy: 0.8847 - val_loss: 3.0320 - val_mae: 0.7342 - val_accuracy: 0.7801\n",
            "Epoch 247/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.0127 - mae: 1.3118 - accuracy: 0.8837 - val_loss: 4.4883 - val_mae: 1.3895 - val_accuracy: 0.8078\n",
            "Epoch 248/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.4320 - mae: 1.4103 - accuracy: 0.8819 - val_loss: 3.8495 - val_mae: 1.0224 - val_accuracy: 0.7638\n",
            "Epoch 249/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.3304 - mae: 1.3792 - accuracy: 0.8785 - val_loss: 5.4562 - val_mae: 1.6871 - val_accuracy: 0.7979\n",
            "Epoch 250/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.0925 - mae: 1.3070 - accuracy: 0.8826 - val_loss: 3.3355 - val_mae: 0.7602 - val_accuracy: 0.7837\n",
            "Epoch 251/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 3.9148 - mae: 1.2901 - accuracy: 0.8782 - val_loss: 3.8138 - val_mae: 1.1350 - val_accuracy: 0.7688\n",
            "Epoch 252/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 3.8685 - mae: 1.2667 - accuracy: 0.8824 - val_loss: 5.6446 - val_mae: 1.7595 - val_accuracy: 0.7801\n",
            "Epoch 253/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.2094 - mae: 1.3523 - accuracy: 0.8817 - val_loss: 3.4205 - val_mae: 0.8219 - val_accuracy: 0.7872\n",
            "Epoch 254/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 3.9957 - mae: 1.3125 - accuracy: 0.8801 - val_loss: 6.3881 - val_mae: 1.9138 - val_accuracy: 0.8092\n",
            "Epoch 255/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.3465 - mae: 1.3674 - accuracy: 0.8830 - val_loss: 3.9972 - val_mae: 1.0257 - val_accuracy: 0.8071\n",
            "Epoch 256/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.2725 - mae: 1.3745 - accuracy: 0.8815 - val_loss: 4.5501 - val_mae: 1.4930 - val_accuracy: 0.7936\n",
            "Epoch 257/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.1007 - mae: 1.3205 - accuracy: 0.8792 - val_loss: 3.9880 - val_mae: 1.2150 - val_accuracy: 0.7723\n",
            "Epoch 258/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 3.9935 - mae: 1.3084 - accuracy: 0.8714 - val_loss: 3.4316 - val_mae: 0.8111 - val_accuracy: 0.8007\n",
            "Epoch 259/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.1359 - mae: 1.3336 - accuracy: 0.8838 - val_loss: 5.7897 - val_mae: 1.7826 - val_accuracy: 0.8021\n",
            "Epoch 260/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.4399 - mae: 1.3995 - accuracy: 0.8821 - val_loss: 3.4693 - val_mae: 0.9776 - val_accuracy: 0.7801\n",
            "Epoch 261/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.2733 - mae: 1.3502 - accuracy: 0.8741 - val_loss: 7.7265 - val_mae: 2.1819 - val_accuracy: 0.7865\n",
            "Epoch 262/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.6595 - mae: 1.4532 - accuracy: 0.8799 - val_loss: 3.4494 - val_mae: 0.8044 - val_accuracy: 0.7879\n",
            "Epoch 263/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.0620 - mae: 1.3336 - accuracy: 0.8824 - val_loss: 2.8802 - val_mae: 0.6796 - val_accuracy: 0.7858\n",
            "Epoch 264/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 3.8827 - mae: 1.3040 - accuracy: 0.8838 - val_loss: 7.3757 - val_mae: 2.0624 - val_accuracy: 0.8113\n",
            "Epoch 265/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.3134 - mae: 1.3750 - accuracy: 0.8883 - val_loss: 4.0589 - val_mae: 1.0127 - val_accuracy: 0.7851\n",
            "Epoch 266/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.1579 - mae: 1.3336 - accuracy: 0.8787 - val_loss: 6.2420 - val_mae: 1.8775 - val_accuracy: 0.7702\n",
            "Epoch 267/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.5700 - mae: 1.4191 - accuracy: 0.8714 - val_loss: 10.8667 - val_mae: 2.6214 - val_accuracy: 0.7879\n",
            "Epoch 268/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.8184 - mae: 1.4476 - accuracy: 0.8759 - val_loss: 4.6598 - val_mae: 1.1464 - val_accuracy: 0.7780\n",
            "Epoch 269/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 5.4231 - mae: 1.3833 - accuracy: 0.8766 - val_loss: 20.2106 - val_mae: 3.6642 - val_accuracy: 0.7979\n",
            "Epoch 270/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 7.6890 - mae: 1.9199 - accuracy: 0.8583 - val_loss: 5.1915 - val_mae: 1.1852 - val_accuracy: 0.7624\n",
            "Epoch 271/400\n",
            "23/23 [==============================] - 9s 372ms/step - loss: 4.8926 - mae: 1.4332 - accuracy: 0.8482 - val_loss: 3.6202 - val_mae: 0.9013 - val_accuracy: 0.8057\n",
            "Epoch 272/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.3781 - mae: 1.3457 - accuracy: 0.8624 - val_loss: 5.1179 - val_mae: 1.1417 - val_accuracy: 0.7816\n",
            "Epoch 273/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.2351 - mae: 1.3404 - accuracy: 0.8739 - val_loss: 4.8443 - val_mae: 1.3398 - val_accuracy: 0.7986\n",
            "Epoch 274/400\n",
            "23/23 [==============================] - 9s 374ms/step - loss: 4.3380 - mae: 1.3694 - accuracy: 0.8663 - val_loss: 9.7842 - val_mae: 2.3437 - val_accuracy: 0.8028\n",
            "Epoch 275/400\n",
            "23/23 [==============================] - 9s 375ms/step - loss: 5.4571 - mae: 1.6172 - accuracy: 0.8615 - val_loss: 4.3544 - val_mae: 1.0881 - val_accuracy: 0.7901\n",
            "Epoch 276/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.2049 - mae: 1.3494 - accuracy: 0.8787 - val_loss: 4.2601 - val_mae: 1.1819 - val_accuracy: 0.7943\n",
            "Epoch 277/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.0616 - mae: 1.2993 - accuracy: 0.8787 - val_loss: 4.6447 - val_mae: 1.3281 - val_accuracy: 0.8106\n",
            "Epoch 278/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.1186 - mae: 1.3299 - accuracy: 0.8755 - val_loss: 4.9483 - val_mae: 1.5029 - val_accuracy: 0.8043\n",
            "Epoch 279/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.1320 - mae: 1.3305 - accuracy: 0.8764 - val_loss: 4.3244 - val_mae: 0.9524 - val_accuracy: 0.7844\n",
            "Epoch 280/400\n",
            "23/23 [==============================] - 9s 373ms/step - loss: 4.2308 - mae: 1.3755 - accuracy: 0.8837 - val_loss: 3.7537 - val_mae: 1.0738 - val_accuracy: 0.8085\n",
            "Epoch 281/400\n",
            "22/23 [===========================>..] - ETA: 0s - loss: 4.3404 - mae: 1.3975 - accuracy: 0.8837"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-42e971d486c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    810\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 step_num=step):\n\u001b[1;32m   1017\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLKZTjQe30wR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/417data/val_acc.txt\", \"w\") as txt:\n",
        "    txt.write(str(history.history['val_accuracy']))\n",
        "print(history.history['val_accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qlh4VVrd3zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp93Wq0SSmuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize history for error\n",
        "plt.plot(history.history['mae'])\n",
        "plt.plot(history.history['val_mae'])\n",
        "plt.title('Model Error')\n",
        "plt.ylabel('mean absolute error')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54sX_kfmImtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKhfAJn67dg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/drive/My Drive/417data/model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/content/drive/My Drive/417data/model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbbiPpmu6FwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.utils import plot_model\n",
        "# plot_model(model, to_file='/content/drive/My Drive/417data/model.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}